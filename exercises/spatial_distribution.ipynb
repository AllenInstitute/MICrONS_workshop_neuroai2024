{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Spatial Distribution Exercise\n",
    "\n",
    "The goal of this tutorial is learn how to characterize what cells exist in the visual cortex volume and how they are distributed across space and cell types.\n",
    "\n",
    "## Note if running on Google Colab\n",
    "\n",
    "If you are running in Google colab, you will need to install a couple of packages to make it work. Just run `pip install caveclient standard_transform` in a cell at the begining of the notebook.\n",
    "\n",
    "Also, you will have to get your token from the [CAVE website](https://global.daf-apis.com/sticky_auth/settings/tokens) and set it by passing an auth token to the CAVEclient directly via `client = CAVEclient(datastack, auth_token=auth_token)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "\n",
    "from caveclient import CAVEclient\n",
    "\n",
    "datastack = 'minnie65_public'\n",
    "client = CAVEclient(datastack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Getting an overview of the cell types in the data\n",
    "\n",
    "Download `aibs_metamodel_mtypes_v661_v2`, a table of cell type predictions throughout the dataset.\n",
    "Look at the effect of the `split_positions` parameter, which can be set to True or False.\n",
    "\n",
    "For simplicity, we will simplify the excitatory cell types in this prediction table using the pandas `replace` function, which takes a dictionary and a dataframe column and maps keys to values.\n",
    "Assuming our cell type dataframe is called `soma_df`, we want to do:\n",
    "\n",
    "```python\n",
    "ct_simplify = {\n",
    "    \"L2a\": \"L2\", # Layer 2 excitatory cell\n",
    "    \"L2b\": \"L2\",\n",
    "    \"L2c\": \"L3\", # Layer 3 excitatory cell\n",
    "    \"L3a\": \"L3\",\n",
    "    \"L3b\": \"L3\",\n",
    "    \"L4a\": \"L4\", # Layer 4 excitatory cell\n",
    "    \"L4b\": \"L4\",\n",
    "    \"L4c\": \"L4\",\n",
    "    \"L5a\": \"L5it\", # Layer 5 cortico-cortical (IT) cell\n",
    "    \"L5b\": \"L5it\",\n",
    "    \"L5ET\": \"L5et\", # Layer 5 subcortical projecting (ET) cell\n",
    "    \"L5NP\": \"L5np\", # Layer 5 near projecting (NP) cell\n",
    "    \"L6short-a\": \"L6it\",  # Layer 6 cortico-cortical (IT) cell\n",
    "    \"L6short-b\": \"L6it\",\n",
    "    \"L6tall-a\": \"L6ct\", # Layer 6 cortico-thalamic (CT) cell\n",
    "    \"L6tall-b\": \"L6ct\",\n",
    "    \"L6tall-c\": \"L6ct\",\n",
    "}\n",
    "\n",
    "soma_df['cell_type'] = soma_df['cell_type'].replace(ct_simplify)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "**Tasks**:\n",
    "1) Run the simplification code above to replace cell type labels.\n",
    "2) Based on this table, what fraction of all neurons are inhibitory?\n",
    "3) What is the most numerous excitatory cell type?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Reorienting the data\n",
    "\n",
    "We are going to use a package called `standard_transform` to make it easier to put the data into a useful coordinate system.\n",
    "The current `pt_position` values are in voxels and can be directly pasted into Neuroglancer.\n",
    "However, usually for analysis we want spatial dimensions like nanometers or microns.\n",
    "Moreover, it's useful if convenient directions like pia-to-white-matter axis correspond to the y-coordinate.\n",
    "\n",
    "**Tasks**\n",
    "\n",
    "Plot the x-y distribution of excitatory neuron cell body locations.\n",
    "Note density as a function of depth, but also slight rotation of dataset.\n",
    "_Hint_: The y-coordinates *increase* as you go down from pia.\n",
    "\n",
    "Next, use the standard_transform function `minnie_ds.transform_vx.apply_dataframe( COLUMN_NAME, DATAFRAME )` that maps voxel coordinates in the column \"COLUMN_NAME\" of a dataframe to microns.\n",
    "The transform will rotate the data by 5 degrees and align y=0 to be near the pial surface.\n",
    "Plot the new x-y distribution of excitatory neuron cell body locations and see how that differs from the untransformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from standard_transform.datasets import minnie_ds\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Soma depths and cell types\n",
    "\n",
    "You can use the optional argument `projection=\"y\"` for the function `minnie_ds.transform_vx.apply_dataframe` to get just the soma depth value and assign it to a column.\n",
    "\n",
    "**Question**\n",
    "What excitatory cell types overlap one another most in depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Different visual areas\n",
    "\n",
    "The MICrONs dataset was taken at the edge of primary visual cortex and higher visual areas RL and AL.\n",
    "We will now look at how cells might differ between primary and higher-order regions.\n",
    "A function that returns True if a location is beyond a linear approximation of the HVAs and False otherwise.\n",
    "\n",
    "**Task**\n",
    "\n",
    "Using the code below, determine if each cell body is a in the HVA or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# These values come from a linear approximation of primary visual cortex/HVA\n",
    "# boundaries in *voxels* before transformation. Make sure to convert units if you want. \n",
    "xz0 = [237415, 26308]\n",
    "xz1 = [286783, 8960]\n",
    "\n",
    "x0 = xz0[0]\n",
    "x1 = xz1[0]\n",
    "z0 = xz0[1]\n",
    "z1 = xz1[1]\n",
    "\n",
    "def soma_in_hva(pt):\n",
    "    ptz = pt[:,2]\n",
    "    ptx = pt[:,0]\n",
    "    x_thresh = x1 + (ptz-z1) * (x0-x1) / (z0-z1)\n",
    "    return ptx > x_thresh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "1) For some location in primary visual cortex and some location in an HVA, compute the excitatory cell density measuring number of cells per unit volume as a function of depth. Depth bins or windows around 30-50 microns work well. Plot a comparison of the cell density profile of the HVA to VISp.\n",
    "\n",
    "2) Compare the relative fraction of excitatory neurons with different cell types. What cell types are much more common in the HVA and which less common?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Extra Credit!\n",
    "\n",
    "As a bonus to help think about the data if you would like, I've pre-computed density profiles every 10 microns through a region along the center of the dataset.\n",
    "This exercise is purely optional.\n",
    "Using whatever data analysis technique you can think of, what areas of the data have similar density profiles?\n",
    "How do these match with the VISp/HVA boundary?\n",
    "\n",
    "The code used to compute density is shown below and the file is in this directory as `density_profile.feather`.\n",
    "You can load this file with `profile_df = pd.read_feather('density_profile.feather')`.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "xvals = np.arange(450, 1301, 10)\n",
    "zvals = np.arange(650, 1051, 10)\n",
    "\n",
    "depths = np.linspace(0,800,100)\n",
    "\n",
    "profiles = []\n",
    "xloc = []\n",
    "zloc = []\n",
    "for xx in tqdm(xvals):\n",
    "    for zz in zvals:\n",
    "        profiles.append(\n",
    "            cell_density(\n",
    "                (xx, zz),\n",
    "                depths,\n",
    "                soma_df.query('classification_system == \"excitatory_neuron\"'),\n",
    "                bin_height=40,\n",
    "                width=50,\n",
    "            )\n",
    "        )\n",
    "        xloc.append(xx)\n",
    "        zloc.append(zz)\n",
    "\n",
    "profile_df = pd.DataFrame(\n",
    "    {\n",
    "        \"xloc\": xloc,\n",
    "        \"zloc\": zloc,\n",
    "        \"profile\": profiles\n",
    "    }\n",
    ")\n",
    "\n",
    "data_df = {\"xloc\": xloc, \"zloc\": zloc}\n",
    "profiles = np.array(profiles)\n",
    "profile_cols = []\n",
    "for ii in range(profiles.shape[1]):\n",
    "    data_df[f\"dep_dens_{ii}\"] = profiles[:,ii]\n",
    "    profile_cols.append(f\"dep_dens_{ii}\")\n",
    "\n",
    "profile_df = pd.DataFrame(data_df)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file described above\n",
    "profile_df = pd.read_feather('density_profile.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cave-release",
   "language": "python",
   "name": "cave-release"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
